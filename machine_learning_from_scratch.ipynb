{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as data\n",
    "import cupy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = data.load_iris()\n",
    "y = data.target\n",
    "X = data.data\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "This notebook was desinged with two purposes in mind. First, I wanted to brush up on the concepts of the most common machine learning algorithms, and create them from scratch, including scoring metrics. Second, I wanted to provide a tutorial for others who are looking to build some intuition for the underlying mechanics of the algorithms involved. I will cover the following algorithms in this notebook:\n",
    "\n",
    "1. Linear Regression (OLS)\n",
    "2. Logistic Regression\n",
    "3. Naieve Bayes Classifier\n",
    "4. K-Nearest Neighbors\n",
    "5. K-Means Clustering\n",
    "6. Support Vector Machines\n",
    "7. Decision Trees\n",
    "8. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression\n",
    "This model uses the ordinary least squares algorithm: $\\hat{\\beta} = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    #TODO: Extend to MLR?\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.coef_ = None\n",
    "        self.fit_predictions = None\n",
    "        self.residuals = None\n",
    "        self.df = None\n",
    "        self.rss = None\n",
    "        self.tss = None\n",
    "        self.mse = None\n",
    "        self.mae = None\n",
    "        self.rmse = None\n",
    "        self.r2 = None\n",
    "        self.adj_r2 = None\n",
    "        self.bic = None\n",
    "        self.aic = None\n",
    "        self.fstat = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, multiple = False, verbose=False):\n",
    "        if multiple:\n",
    "            pass\n",
    "        # Add a column of ones at position zero to calculate the model intercept\n",
    "        X = np.hstack((np.ones((X.shape[0],1)),X))\n",
    "        # Calculate a = X^(T)X\n",
    "        a_1 = X.T @ X\n",
    "        # Calculate a^(-1)\n",
    "        a_inv = np.linalg.inv(a_1)\n",
    "        # calculate a_2 = a^(-1)X^(T) again\n",
    "        a_2 = a_inv @ X.T\n",
    "        # calculate the coefficient vector\n",
    "        beta_hat = a_2 @ y\n",
    "        self.coef_ = beta_hat\n",
    "        \n",
    "        # Make and store predictions based on fitted model training data\n",
    "        preds = []\n",
    "        for i in range(X.shape[0]):\n",
    "            pred = self.coef_[0]\n",
    "            for j in range(self.coef_.shape[0]-1):\n",
    "                pred += self.coef_[j+1]*X[i,j+1]\n",
    "            preds.append(pred)   \n",
    "        \n",
    "        self.fit_predictions = np.array(preds)  \n",
    "\n",
    "        # Calculate model scores\n",
    "        self.residuals = y-preds \n",
    "        n = X.shape[0] # number of observations\n",
    "        p = X.shape[1] # number of predictors\n",
    "        self.residual_df = n-p\n",
    "        self.model_df = p\n",
    "        self.rss = np.sum(self.residuals**2)\n",
    "        self.tss = np.sum((y-(np.mean(y)))**2)\n",
    "        self.mae = np.sum(np.abs(self.residuals))/n\n",
    "        self.mse = self.rss/n\n",
    "        self.rmse = np.sqrt(self.mse)\n",
    "        self.r2 = 1-(self.rss/self.tss)\n",
    "        self.adj_r2 = 1-((1-self.r2)*(n-1))/(n-p-1)  \n",
    "        self.aic = (2*p)-(n*np.log(self.rss))      \n",
    "\n",
    "        if verbose:\n",
    "            #TODO: Build out model summary output, maybe it needs its own method\n",
    "            pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        #TODO: Should the fit method call this with the training data?\n",
    "        preds = []\n",
    "        for i in range(X.shape[0]):\n",
    "            pred = 0\n",
    "            for idx,coef in enumerate(lm.coef_):\n",
    "                pred += coef*X[i,idx]\n",
    "            preds.append(pred)   \n",
    "        \n",
    "        return np.array(preds)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18649525 -0.11190585 -0.04007949  0.22864503  0.60925205]\n",
      "[[ 0.19211862  0.07391778  0.49722661  0.11067328  0.12606371]\n",
      " [-0.07603363 -0.15970266  0.42881137 -0.06372103 -0.12935406]\n",
      " [ 0.52903089 -0.24298621  0.14166483 -0.57938575  0.15167624]]\n"
     ]
    }
   ],
   "source": [
    "# this implementation\n",
    "lm = LinearRegression()\n",
    "\n",
    "lm.fit(X,y)\n",
    "\n",
    "print(lm.coef_)\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "# create a random matrix:\n",
    "A = np.random.normal(size=(5,2))\n",
    "\n",
    "# add a column of zeros to it:\n",
    "A = np.hstack((np.ones((A.shape[0],1)),A))\n",
    "\n",
    "print(pinv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          2.03219578  0.16612443]\n",
      " [ 1.          0.33459659 -0.72356847]\n",
      " [ 1.          0.00639409 -0.26058593]\n",
      " [ 1.         -3.25596154  0.38935975]\n",
      " [ 1.          0.55300325  1.3364459 ]]\n"
     ]
    }
   ],
   "source": [
    "# create a random matrix:\n",
    "A = np.random.normal(size=(5,2))\n",
    "\n",
    "# add a column of zeros to it:\n",
    "print(np.hstack((np.ones((A.shape[0],1)),A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18649524720625021\n",
      "0.9303939218549564\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# from sklearn -> model doesnt match, close but not perfect...\n",
    "import sklearn.linear_model as lr\n",
    "lm = lr.LinearRegression()\n",
    "\n",
    "lm.fit(X,y)\n",
    "print(lm.intercept_)\n",
    "print(lm.score(X,y))\n",
    "print(np.mean(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.972\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.971\n",
      "Method:                 Least Squares   F-statistic:                              1267.\n",
      "Date:                Thu, 18 Nov 2021   Prob (F-statistic):                   3.17e-112\n",
      "Time:                        23:02:19   Log-Likelihood:                          17.009\n",
      "No. Observations:                 150   AIC:                                     -26.02\n",
      "Df Residuals:                     146   BIC:                                     -13.98\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0845      0.049     -1.720      0.088      -0.182       0.013\n",
      "x2            -0.0236      0.057     -0.415      0.679      -0.136       0.089\n",
      "x3             0.2249      0.057      3.968      0.000       0.113       0.337\n",
      "x4             0.5997      0.094      6.392      0.000       0.414       0.785\n",
      "==============================================================================\n",
      "Omnibus:                        0.384   Durbin-Watson:                   1.149\n",
      "Prob(Omnibus):                  0.825   Jarque-Bera (JB):                0.128\n",
      "Skew:                          -0.026   Prob(JB):                        0.938\n",
      "Kurtosis:                       3.133   Cond. No.                         50.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Check with statsmodels library\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa673704ded31be95838478056e1307514606af089582566ca2854b920b0927"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
