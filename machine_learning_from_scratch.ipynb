{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning From Scratch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "import sklearn.datasets as data \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = data.load_iris()\n",
    "y = data.target\n",
    "X = data.data\n",
    "\n",
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction:\n",
    "\n",
    "This notebook was desinged with two purposes in mind. First, I wanted to brush up on the concepts of the most common machine learning algorithms, and create them from scratch, including scoring metrics. Second, I wanted to provide a tutorial for others who are looking to build some intuition for the underlying mechanics of the algorithms involved. I will cover the following algorithms in this notebook:\n",
    "\n",
    "- Linear Regression (OLS)\n",
    "- Logistic Regression\n",
    "- Naieve Bayes Classifier\n",
    "- K-Nearest Neighbors\n",
    "- K-Means Clustering\n",
    "- Support Vector Machines\n",
    "- Decision Trees\n",
    "- Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression\n",
    "This model uses the ordinary least squares algorithm:\n",
    "$$\n",
    "\\hat{\\beta} = (X^TX)^{-1}X^Ty\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.coef_ = None\n",
    "        self.fit_predictions = None\n",
    "        self.residuals = None\n",
    "        self.df = None\n",
    "        self.rss = None\n",
    "        self.tss = None\n",
    "        self.mse = None\n",
    "        self.mae = None\n",
    "        self.rmse = None\n",
    "        self.r2 = None\n",
    "        self.adj_r2 = None\n",
    "        self.bic = None\n",
    "        self.aic = None\n",
    "        self.fstat = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        # Calculate a = X^(T)X\n",
    "        a_1 = X.T @ X\n",
    "        # Calculate a^(-1)\n",
    "        a_inv = np.linalg.inv(a_1)\n",
    "        # calculate b = a^(-1)X^(T) again\n",
    "        a_2 = a_inv @ X.T\n",
    "        # calculate the coefficient vector\n",
    "        beta_hat = a_2 @ y\n",
    "        self.coef_ = beta_hat\n",
    "        \n",
    "        # Make and store predictions based on fitted model training data\n",
    "        preds = []\n",
    "        for i in range(X.shape[0]):\n",
    "            pred = 0\n",
    "            for idx,coef in enumerate(lm.coef_):\n",
    "                pred += coef*X[i,idx]\n",
    "            preds.append(pred)   \n",
    "        \n",
    "        self.fit_predictions = np.array(preds)  \n",
    "\n",
    "        # Calculate model scores\n",
    "        self.residuals = y-preds \n",
    "        n = X.shape[0] # number of observations\n",
    "        p = X.shape[1] # number of predictors\n",
    "        self.residual_df = n-p\n",
    "        self.model_df = p\n",
    "        self.rss = np.sum(self.residuals**2)\n",
    "        self.tss = np.sum((y-(np.mean(y)))**2)\n",
    "        self.mae = np.sum(np.abs(self.residuals))/n\n",
    "        self.mse = self.rss/n\n",
    "        self.rmse = np.sqrt(self.mse)\n",
    "        self.r2 = 1-(self.rss/self.tss)\n",
    "        self.adj_r2 = 1-((1-self.r2)*(n-1))/(n-p-1)\n",
    "\n",
    "        \n",
    "\n",
    "        if verbose:\n",
    "            #print the model output\n",
    "            pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make and store predictions based on fitted model and testing data\n",
    "        preds = []\n",
    "        for i in range(X.shape[0]):\n",
    "            pred = 0\n",
    "            for idx,coef in enumerate(lm.coef_):\n",
    "                pred += coef*X[i,idx]\n",
    "            preds.append(pred)   \n",
    "        \n",
    "        return np.array(preds)\n",
    "        \n",
    "        \n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "lm.fit(X,y)\n",
    "\n",
    "lm.r2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9299960156084729"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "preds = []\n",
    "for i in range(X.shape[0]):\n",
    "    pred = 0\n",
    "    for idx,coef in enumerate(lm.coef_):\n",
    "        pred += coef*X[i,idx]\n",
    "    preds.append(pred)\n",
    "preds = np.array(preds)\n",
    "\n",
    "# print(preds.shape)\n",
    "# print(preds)\n",
    "# print(y)\n",
    "\n",
    "\n",
    "print('MAE: ' + str(mae) + '\\n',\n",
    "        'MSE: ' + str(mse) + '\\n',\n",
    "        'RMSE: ' + str(rmse))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.06610507853286897\n",
      " MSE: 0.004500539282329266\n",
      " RMSE: 0.06708605877773166\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "print(results.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.972\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.971\n",
      "Method:                 Least Squares   F-statistic:                              1267.\n",
      "Date:                Sun, 12 Sep 2021   Prob (F-statistic):                   3.17e-112\n",
      "Time:                        21:18:30   Log-Likelihood:                          17.009\n",
      "No. Observations:                 150   AIC:                                     -26.02\n",
      "Df Residuals:                     146   BIC:                                     -13.98\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0845      0.049     -1.720      0.088      -0.182       0.013\n",
      "x2            -0.0236      0.057     -0.415      0.679      -0.136       0.089\n",
      "x3             0.2249      0.057      3.968      0.000       0.113       0.337\n",
      "x4             0.5997      0.094      6.392      0.000       0.414       0.785\n",
      "==============================================================================\n",
      "Omnibus:                        0.384   Durbin-Watson:                   1.149\n",
      "Prob(Omnibus):                  0.825   Jarque-Bera (JB):                0.128\n",
      "Skew:                          -0.026   Prob(JB):                        0.938\n",
      "Kurtosis:                       3.133   Cond. No.                         50.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3fa673704ded31be95838478056e1307514606af089582566ca2854b920b0927"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}